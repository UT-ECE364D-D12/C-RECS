batch_size: 64

train:
  max_epochs: 5
  accumulation_steps: 1

loss_weights:
  mse: 10.0
  id: 0.0
  triplet: 10.0
  variance: 0.8
  invariance: 0.8
  covariance: 0.08

optimizer:
  encoder:
    lr: 0.0001
    weight_decay: 0.01
  classifier:
    lr: 0.001
    weight_decay: 0.01
  expander:
    lr: 0.001
    weight_decay: 0.01
  recommender:
    lr: 0.001
    weight_decay: 0.01