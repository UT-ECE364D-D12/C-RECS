name: "ml-20m ModernBERT 8k Users MNRL Better Duplicate Masking"
random_seed: 42
batch_size: 128

model:
  recommender:
    embed_dim: 768
    mlp_dims: [768, 768]
    dropout: 0.5
    # weights: "weights/recommender/deepfm.pt"

  encoder:
    model_name: "answerdotai/ModernBERT-base"
    embedding_dropout: 0.2
    mlp_dropout: 0.2
    attention_dropout: 0.2
    weights: NULL


classifier:
  embed_dim: 768
  dropout: 0.0

expander:
  embed_dim: 768
  width: 2.0
  dropout: 0.5

criterion:
  triplet_scale: 20
  # triplet_margin: 1.2
  focal_gamma: 0.75
  vicreg_gamma: 1.0
  loss_weights:
    mse: 5.5
    id: 3.2
    triplet: 8.3
    variance: 0.9
    invariance: 0.75
    covariance: 0.45


optimizer:
  all:
    amsgrad: True
    betas: [0.9, 0.98]
    eps: 1.0e-6
  encoder:
    lr: 8.0e-5
    weight_decay: 0.05
  classifier:
    lr: 1.0e-4
    weight_decay: 0.05
  expander:
    lr: 1.0e-4
    weight_decay: 0.01
  recommender:
    lr: 1.0e-4
    weight_decay: 0.1

train:
  max_epochs: 3
  accumulation_steps: 1