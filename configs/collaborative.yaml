name: "ml-20m"
random_seed: 42
batch_size: 64

train:
  max_epochs: 2
  accumulation_steps: 1

criterion:
  triplet_margin: 1.0
  focal_gamma: 0.0
  vicreg_gamma: 1.0
  max_rank: 50
  loss_weights:
    mse: 10.0
    id: 0.1
    triplet: 10.0
    variance: 0.8
    invariance: 0.8
    covariance: 0.08

optimizer:
  encoder:
    lr: 0.000005
    weight_decay: 0.01
  classifier:
    lr: 0.0001
    weight_decay: 0.01
  expander:
    lr: 0.0001
    weight_decay: 0.01
  recommender:
    lr: 0.0001
    weight_decay: 0.01

encoder:
  model_name: "bert-base-uncased"
  hidden_dropout_prob: 0.0
  weights: NULL

recommender:
  embed_dim: 768
  mlp_dims: [768, 768]
  dropout: 0.8
  weights: NULL